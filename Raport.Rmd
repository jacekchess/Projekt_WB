---
title: "Comparision of efficiency of various data imputation techniques in R"
author: "Agata Makarewicz, Martyna Majchrzak, Jacek Wiśniewski"
date: "27 04 2020"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, inlude=FALSE, results = 'hide')
library(tidyverse)
source('evaluate_imputations.R')
source('load_datasets.R')
```

## Abstract

Imputation of missing observations is a common step of machine learning process and sometimes a difficult problem. Many real-life datasets are incomplete and ... to be continued XD

## Introduction 

The aim of this report is to measure the influence of five different imputation methods on the performance of a Recursive Partitioning And Regression Trees  classification model. To achieve this goal the following experiment will be conducted on 10 datasets, gathered mostly from OpenML and some from the imputation packages. 

## Methodology 

In the following table are presented the datasets used for this experiment, along with their OpenML ID number, name, number of instances and number of features. The datasets vary in size and number of missing values.


```{r, results='markup'}
data_nr <- c("1590", "188", "27", "29", "38", "4", "40536", "55", "56", "944")
data_name <- c("adult", "eucalyptus", "colic", "credit-approval", "sick", "labor", "SpeedDating", "hepatitis", "vote", "echoMonths" )
nr_instances <- c(48842, 736, 368, 690, 3772, 57, 8378, 155, 435, 130)
nr_features <- c(13, 16, 20, 16, 28, 17, 123, 20, 17, 10)

datasets <- data.frame(cbind(data_nr, 
                     data_name, 
                     nr_instances, 
                     nr_features))
# colnames(datasets)
knitr::kable(datasets)
```

### Imputation strategies

The imputations, that were performed and analyzed include:

* **mean/mode imputation**\
  One of the basic techniques, replaces missing values with mean (for continuous variables) and mode (for categorical variables) of complete values in given variable. Implemented with basic R functions.

* **mice (predictive mean matching)**\
   Performs multivariate imputation by chained equations, meaning it creates multiple imputations (replacement values) for multivariate missing data. Implemented with mice() function (with method parameter set to "pmm") from mice package.

* **k-nearest neighbours**\
  An aggregation of the non-missing values of the k nearest neighbors is used as imputed value. The kind of aggregation depends on the type of the variable.Implemended with kNN() function from VIM package.
  
* **hotdeck** \
  Each missing value is replaced with an observed response from a “similar” unit. Implemented with hotdeck() function from VIM package.

* **softImpute combined with median/mode imputation**\
  For numeric variables function softImpute() from softImpute package is used, fitting a low-rank matrix approximation to a matrix with missing values via nuclear-norm regularization. For remaining variables missing values are imputed with median or mode, which is implemented with impute() function from imputeMissings() package.

### Implementation

To conduct the experiment a function **evaluate_imputations()** placed in the script with the same name was implemented. The function receives as arguments:

* a single dataset to impute 
* a name of the target variable

Dataset is splitted into train set (80% of observation) and train set (20% of observation).
They are imputed separately, using methods described above, in order do avoid data leakage.
Afterwards modelling is performed, using mlr3 package.Recursive Partitioning And Regression Trees learner is trained on train set and then prediction on test set are made. 
Two evaluate the model performance two metrics are used:

* **AUC**\
  Area under the curve; represents degree or measure of separability. The probability that the model ranks a random positive example more highly than a random negative example.
  
* **Balanced Accuracy** \
  Arythmetic mean of the TPR (Sensitivity) and FPR (Specificity). 
  Balanced Accuracy is used instead of standard Accuracy (measures how good model is in corectly predicting both positive and negative cases), because some of the datasets are imbalanced, and due to that fact "normal" accuracy may not be proper (cost of misclassification of minority class instance is higher than for majority class instance).

The function returns a matrix with 5 described imputations as rows and 2 performance measures as columns.

## Results

```{r small data, cache=TRUE, warning=FALSE, results='hide'}
# numery wszystkich zbiorów: 1018, 1590, 188, 23381, 27, 29, 38, 4, 40536, 41278, 55, 56, 6332, 944

# numery używanych obecnie: 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944

###################### GIT ZBIORKI: 944, 56, 55, 38, 27, 188, 29, 4

evaluation_944 <- evaluate_imputations(dataset944,target944)
evaluation_56 <- evaluate_imputations(dataset56,target56) 
evaluation_55 <- evaluate_imputations(dataset55,target55)
evaluation_38 <- evaluate_imputations(dataset38,target38) # długi missForest 
evaluation_27 <- evaluate_imputations(dataset27,target27)
evaluation_188 <- evaluate_imputations(dataset188,target188)
evaluation_29 <- evaluate_imputations(dataset29,target29) 
# działa przy ustawieniu pmm w mice, inaczej nie
evaluation_4 <- evaluate_imputations(dataset4,target4) 
# przy rm rows zeruje sie zbiór testowy, treningowy ma jeden wiersz 

############################### PROBLEMY: 1018
# evaluation_1018 <- evaluate_imputations(dataset1018,target1018)
# przy rm rows zeruje sie zbiór testowy
# przy mice nie działa dla "pmm"


```

```{r big data 1, cache=TRUE, warning=FALSE}

############################### DUŻE ZBIORKI: 41278, 6332, 40536, 1590, 23381

# na potrzeby duzych zbiorów w mice jest 1x1 , pmm i dodatkowy parametr zeby te weights sie nie wywalało 
# wykomentowane bo długo sie mielą i wywalaja sesje R czasami xd
# testowałam funkcję ręcznie na data_test dla kazdego zbioru bo dla nich jeszcze w miare sie robiło
# wiec mysle ze na train tez powinno działać xd



# ten zbiór jest zjebany bo mega duży, wywalił mi sesje 3 razy wiec moze go olejmy 
# evaluation_41278 <- evaluate_imputationss(dataset41278,target41278) 

```

```{r big data 2, cache=TRUE}
evaluation_40536 <- evaluate_imputations(dataset40536,target40536) 
```

```{r big data 3, cache=TRUE}
# evaluation_23381 <- evaluate_imputations(dataset23381,target23381) # nie działa :( 
```

```{r big data 4, cache=TRUE}
### do sprawdzenia, długo sie robi ale moze pojdzie 
# evaluation_6332 <- evaluate_imputations(dataset6332,target6332) 
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r big data 5, cache=TRUE}
evaluation_1590 <- evaluate_imputations(dataset1590,target1590) 
```

```{r, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
auc_combined<-as.data.frame(
  rbind(
  evaluation_1590$auc,
  evaluation_188$auc,
  # evaluation_23381$auc,
  evaluation_27$auc,
  evaluation_29$auc,
  evaluation_38$auc,
  evaluation_4$auc,
  evaluation_40536$auc,
  evaluation_55$auc,
  evaluation_56$auc,
  # evaluation_6332$auc,
  evaluation_944$auc
))
colnames(auc_combined)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')

bacc_combined<-as.data.frame(
  rbind(
  evaluation_1590$bacc,
  evaluation_188$bacc,
  # evaluation_23381$bacc,
  evaluation_27$bacc,
  evaluation_29$bacc,
  evaluation_38$bacc,
  evaluation_4$bacc,
  evaluation_40536$bacc,
  evaluation_55$bacc,
  evaluation_56$bacc,
  # evaluation_6332$bacc,
  evaluation_944$bacc
))

colnames(bacc_combined)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
knitr::kable(auc_combined)
knitr::kable(bacc_combined)

boxplot(auc_combined, main = "AUC performance")
boxplot(bacc_combined, main = "BACC performance")
```


