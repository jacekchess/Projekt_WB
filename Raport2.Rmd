---
title: "Comparision of efficiency of various data imputation techniques in R"
author: "Agata Makarewicz, Martyna Majchrzak, Jacek Wiśniewski"
date: "27 04 2020"
output: html_document
---

```{r setup, include=TRUE, warning=FALSE, echo=FALSE, resuls='hide', include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, cache=FALSE)
library(tidyverse)
library(reshape2)
library(dplyr)
library(xgboost)
library(kknn)
library(purrr)
source('imputations_performance.R')
source('load_datasets.R')
```

## Abstract

Imputation of missing values is a common step of machine learning process and sometimes a difficult problem. Many real-life datasets contain incomplete observations and dealing with them is key part of modelling as most of the algorithms provided by widely used R packages (for instance caret or mlr) require complete data.
The aim of this report is to measure the influence of five different imputation methods on the performance of a selected classification model. Simple, common methods such as basic mean, median and mode are compared with advanced imputation techniques from specialized R packages - mice, VIM and softImpute.
As a tested algorithms, Recursive Partitioning And Regression Trees, Naive Bayes, Ranger (Random forest),  Linear Discriminant Analysis and k-Nearest Neighbours were chosen.
It's prediction effectiveness is assessed by F1 measure (also called F1 score) to provide a proper measure for both balanced and imbalanced data.\

## Introduction 

Dealing with missing values is an important part of reprocessing data used for machine learning models, because they do not accept incomplete observations.
There are many methods which allow to handle this issue. 
Firstly, there are basic ones such as removing rows or imputing with mean or mode, which are fast and easy to implement, however they do not guarantee a very good performance. On the other hand, many sophisticated strategies exist, e.g. using tree-based models, which usually result in better models, but enhance algorithm's complexity and computional time.
In this paper the quality of 5 different approaches to data imputation is compared, and their impact on binary classification data modelling is assessed.
Summary of the results presents which imputations contributed to achiving the best model's predictions. 
To achieve the goal of this study the following experiment will be conducted on 11 datasets, gathered mostly from OpenML and some from the imputation packages.

## Methodology 

In the following table are presented the datasets used for this experiment, along with their OpenML ID number, name, number of instances, number of features and number of missing values. The datasets vary in size and number of missing values.


```{r dataset table, results='hide'}
library(dplyr)
data_nr <- c("1590", "188", "27", "29", "38", "4", "40536", "55", "56", "6332", "944")
data_name <- c("adult", "eucalyptus", "colic", "credit-approval", "sick", "labor", "SpeedDating", "hepatitis", "vote", "cylinder-bands", "echoMonths" )
nr_instances <- c(48842, 736, 368, 690, 3772, 57, 8378, 155, 435, 540, 130)
nr_features <- c(13, 16, 20, 16, 28, 17, 123, 20, 17, 34, 10)
nr_missing<-c(6465, 455, 1199, 67, 2293, 326, 18570, 167, 392, 999, 97)

datasets <- data.frame(cbind(data_nr, 
                     data_name, 
                     nr_instances, 
                     nr_features,
                     nr_missing))

datasets1<-datasets%>%
  transmute(data_nr=data_nr,
            data_name=data_name,
            nr_instances=as.numeric(as.character(nr_instances)),
            nr_features=as.numeric(as.character(nr_features)),
            nr_missing=as.numeric(as.character(nr_missing)))%>%
  mutate(procent_missing=round(nr_missing/(nr_instances*nr_features),2))
# colnames(datasets)

```

```{r tab1, resuls='hide'}
knitr::kable(datasets1, caption = "Tab.1. Datasets")
```

### Imputation strategies

The imputations, that were performed and analyzed include:

* **mean/mode imputation**\
  One of the basic techniques, replaces missing values with mean (for continuous variables) and mode (for categorical variables) of complete values in given variable. Implemented with basic R functions.

* **mice (predictive mean matching)**\
   Performs multivariate imputation by chained equations, meaning it creates multiple imputations (replacement values) for multivariate missing data. Implemented with mice() function (with method parameter set to "pmm") from mice package.

* **k-nearest neighbours**\
  An aggregation of the non-missing values of the k nearest neighbors is used as imputed value. The kind of aggregation depends on the type of the variable.Implemended with kNN() function from VIM package.
  
* **hotdeck** \
  Each missing value is replaced with an observed response from a “similar” unit. Implemented with hotdeck() function from VIM package.

* **softImpute combined with median/mode imputation**\
  For numeric variables function softImpute() from softImpute package is used, fitting a low-rank matrix approximation to a matrix with missing values via nuclear-norm regularization. For remaining variables missing values are imputed with median or mode, which is implemented with impute() function from imputeMissings() package.
  
### Classification algorithms

Five different algorithms were chosen, two linear classifiers (NB, LDA), two tree-based models (RPART, Ranger) and one kernel estimation (KNN) were tested after every imputation on every dataset. The modelling was performed using mlr3 package.

* **RPART (Recursive Partitioning And Regression Trees)**\
  Based on decision trees, works by splitting the dataset recursively, until a predetermined termination criterion is reached or no improvement can be made.  At each step, the split is made based on the independent variable that splits the data best (results in the largest possible reduction in heterogeneity of the dependent (predicted) variable).
  
* **NB (Naive Bayes)**\
  Technique based on an assumption of independence between predictors (every pair of features being classified is independent of each other) and their equal contribution to the outcome, then the probability of an event occurring given the probability of another event that has already occurred is calculated.
  
* **Ranger (Random forest)**\
  Constructs a large number of individual decision trees that operate as an ensemble, each individual tree returns a class prediction and the class that is the mode of the classes (in case of classification) of the individual trees becomes our model’s prediction.
  
* **LDA (Linear Discriminant Analysis)**\

* **KNN (k-Nearest Neighbour)**\
  An object is classified by a majority vote of its neighbors, being assigned to the class most common among its k nearest neighbors. The neighbours are measured by a distance function.

### Implementation

To conduct the experiment two functions were written:

 * **save_files()** - takes a dataset, divides it into train and test datasets, imputes them in 5 ways described above and saves the imputed datasets into files

Dataset is splitted into train set (80% of observation) and train set (20% of observation).
They are imputed separately, using methods described above, in order do avoid data leakage.

 * **imputations_performance()** - takes dataset name and classification algorithm, returns performance of each dataset imputation combined with this algorithm

The performance is checked using **F1 Measure** -  the harmonic mean of the precision and recall.
 
 $$F_1=2*\frac{precision*recall}{precision+recall}$$
 
Due to that measure .... <RANKING>
 

## Results

### Results Rpart

```{r small data, results='hide'}
# numery wszystkich zbiorów: 1018, 1590, 188, 23381, 27, 29, 38, 4, 40536, 41278, 55, 56, 6332, 944

# numery używanych obecnie: 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944

###################### GIT ZBIORKI: 944, 56, 55, 38, 27, 188, 29, 4

evaluation_944_rpart <- imputations_performance(target944, "dataset944", "classif.rpart")
evaluation_56_rpart <- imputations_performance(target56, "dataset56", "classif.rpart") 
evaluation_55_rpart <- imputations_performance(target55,  "dataset55", "classif.rpart")
evaluation_38_rpart <- imputations_performance(target38,  "dataset38", "classif.rpart") # długi missForest 
evaluation_27_rpart <- imputations_performance(target27,  "dataset27", "classif.rpart")
evaluation_188_rpart <- imputations_performance(target188, "dataset188", "classif.rpart") 
evaluation_29_rpart <- imputations_performance(target29, "dataset29", "classif.rpart") 
# działa przy ustawieniu pmm w mice, inaczej nie
evaluation_4_rpart <- imputations_performance(target4,  "dataset4", "classif.rpart") 
# evaluation_4_rpart <- rep(NA, 5)
# przy rm rows zeruje sie zbiór testowy, treningowy ma jeden wiersz

############################### PROBLEMY: 1018
# evaluation_1018 <- imputations_performance(dataset1018,target1018)
# przy rm rows zeruje sie zbiór testowy
# przy mice nie działa dla "pmm"


```

```{r big data 1, results='hide'}

############################### DUŻE ZBIORKI: 41278, 6332, 40536, 1590, 23381

# na potrzeby duzych zbiorów w mice jest 1x1 , pmm i dodatkowy parametr zeby te weights sie nie wywalało 
# wykomentowane bo długo sie mielą i wywalaja sesje R czasami xd
# testowałam funkcję ręcznie na data_test dla kazdego zbioru bo dla nich jeszcze w miare sie robiło
# wiec mysle ze na train tez powinno działać xd



# ten zbiór jest zjebany bo mega duży, wywalił mi sesje 3 razy wiec moze go olejmy 
# evaluation_41278 <- imputations_performance(target41278,"dataset41278", "classif.rpart") 

```

```{r big data 2, results='hide'}
evaluation_40536_rpart <- imputations_performance(target40536,  "dataset40536", "classif.rpart")
```

```{r big data 3, results='hide'}
# evaluation_23381 <- imputations_performance(target23381, "dataset23381", "classif.rpart") # nie działa :( 
```

```{r big data 4, results='hide'}
### do sprawdzenia, długo sie robi ale moze pojdzie 
evaluation_6332_rpart <- imputations_performance(target6332, "dataset6332", "classif.rpart") 
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r big data 5, results='hide'}
evaluation_1590_rpart <- imputations_performance(target1590, "dataset1590", "classif.rpart") 
```

```{r f1 rpart, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
f1_combined_rpart<-as.data.frame(
  rbind(
  evaluation_1590_rpart$f1,
  evaluation_188_rpart$f1,
  #evaluation_23381$auc,
  evaluation_27_rpart$f1,
  evaluation_29_rpart$f1,
  evaluation_38_rpart$f1,
  evaluation_4_rpart$f1,
  # evaluation_4_rpart,
  evaluation_40536_rpart$f1,
  #evaluation_41278_rpart$f1,
  evaluation_55_rpart$f1,
  evaluation_56_rpart$f1,
  evaluation_6332_rpart$f1,
  evaluation_944_rpart$f1
))
rownames(f1_combined_rpart) <- NULL
colnames(f1_combined_rpart)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
f1_combined_rpart<-cbind(data_name, f1_combined_rpart)

```

```{r tab2, resuls='hide'}
knitr::kable(f1_combined_rpart, caption = "Tab.2. Rpart results")
```

```{r old rating function}

# ranking<-function(f1_combined){
#   
# 
#   df <- transpose(f1_combined[, -1], keep.names = "variable")
#   mean <- colMeans(f1_combined[, -1])
#   min <- apply(f1_combined[, -1], 2, min)
#   max <- apply(f1_combined[, -1], 2, max)
#   df <- cbind(df, mean, min, max)
#   
#   df <- df %>%
#     mutate(rank_min = dense_rank(min)) %>%
#     mutate(rank_mean = dense_rank(mean)) %>%
#     mutate(rank_max = dense_rank(max)) %>%
#     mutate(value = rowSums(.[16:18])/15)
#   
#   df_ranks<-df%>%
#     arrange(desc(value))%>%
#     cbind(ranks=c(1,2,3,4,5))%>%
#     select(variable, ranks)
#   
#   df<-df%>%
#     inner_join(df_ranks, by=c("variable"="variable"))
#   
#   return(df)
# }


```

```{r ranking function}

ranking<-function(f1_combined){
  df <- transpose(f1_combined[, -1], keep.names = "imputation")
  ranks<-as.data.frame(lapply(df%>%select(-imputation), dense_rank))%>%
    mutate(imputation=df$imputation)
  ranks[is.na(ranks)]<-5
  ranks<-ranks%>%select(12, 1:11)
  colnames(ranks)<-c("imputation",data_name)
  
  ranks<-cbind(ranks, mean=rowMeans(ranks[2:12]))
  
  return(ranks)
}

```

### Ranking Rpart

```{r rating rpart, results='hide'}

ranking_rpart<-ranking(f1_combined_rpart)
ranking_rpart_melt<-melt(ranking_rpart%>%select(-mean))

ggplot(ranking_rpart_melt, aes(x = imputation, y = value)) +
  geom_boxplot()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
  
  
```

### Results Naive Bayes

```{r nb 1, results='hide'}
# numery wszystkich zbiorów: 1018, 1590, 188, 23381, 27, 29, 38, 4, 40536, 41278, 55, 56, 6332, 944

# numery używanych obecnie: 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944

###################### GIT ZBIORKI: 944, 56, 55, 38, 27, 188, 29, 4

evaluation_944_nb <- imputations_performance(target944, "dataset944", "classif.naive_bayes")
evaluation_56_nb <- imputations_performance(target56, "dataset56", "classif.naive_bayes") 
evaluation_55_nb <- imputations_performance(target55,  "dataset55", "classif.naive_bayes")
evaluation_38_nb <- imputations_performance(target38,  "dataset38", "classif.naive_bayes")  
evaluation_27_nb <- imputations_performance(target27,  "dataset27", "classif.naive_bayes")
evaluation_188_nb <- imputations_performance(target188, "dataset188", "classif.naive_bayes") 
evaluation_29_nb <- imputations_performance(target29, "dataset29", "classif.naive_bayes") 
# działa przy ustawieniu pmm w mice, inaczej nie
evaluation_4_nb <- imputations_performance(target4,  "dataset4", "classif.naive_bayes") # BŁĄD
# evaluation_4_nb <- rep(NA, 5)
# przy rm rows zeruje sie zbiór testowy, treningowy ma jeden wiersz

############################### PROBLEMY: 1018
# evaluation_1018 <- imputations_performance(dataset1018,target1018)
# przy rm rows zeruje sie zbiór testowy
# przy mice nie działa dla "pmm"


```

```{r nb 2, results='hide'}
evaluation_40536_nb <- imputations_performance(target40536,  "dataset40536", "classif.naive_bayes")
```

```{r nb 3, results='hide'}
# evaluation_23381 <- imputations_performance(target23381, "dataset23381", "classif.naive_bayes") # nie działa :( 
```

```{r nb 4, results='hide'}
### do sprawdzenia, długo sie robi ale moze pojdzie 
evaluation_6332_nb <- imputations_performance(target6332, "dataset6332", "classif.naive_bayes") 
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r nb 5, results='hide'}
evaluation_1590_nb <- imputations_performance(target1590, "dataset1590", "classif.naive_bayes") 
```

```{r f1 nb, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
f1_combined_nb<-as.data.frame(
  rbind(
  evaluation_1590_nb$f1,
  evaluation_188_nb$f1,
  #evaluation_23381$auc,
  evaluation_27_nb$f1,
  evaluation_29_nb$f1,
  evaluation_38_nb$f1,
  evaluation_4_nb$f1,
  # evaluation_4_nb,
  evaluation_40536_nb$f1,
  #evaluation_41278_nb$f1,
  evaluation_55_nb$f1,
  evaluation_56_nb$f1,
  evaluation_6332_nb$f1,
  evaluation_944_nb$f1
))
rownames(f1_combined_nb) <- NULL
colnames(f1_combined_nb)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
f1_combined_nb<-cbind(data_name, f1_combined_nb)

```

```{r tab3, resuls='hide'}
knitr::kable(f1_combined_nb, caption = "Tab.3. Naive Bayes results")
```

### Ranking Naive Bayes

```{r rating nb, results='hide'}
ranking_nb<-ranking(f1_combined_nb)
ranking_nb_melt<-melt(ranking_nb%>%select(-mean))

ggplot(ranking_nb_melt, aes(x = imputation, y = value)) +
  geom_boxplot()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
  
```


### Results Ranger 

```{r ranger 1, results='hide'}

evaluation_944_ranger <- imputations_performance(target944, "dataset944", "classif.ranger")   
evaluation_56_ranger <- imputations_performance(target56, "dataset56", "classif.ranger") 
evaluation_55_ranger <- imputations_performance(target55,  "dataset55", "classif.ranger")  
evaluation_38_ranger <- imputations_performance(target38,  "dataset38", "classif.ranger")  
evaluation_27_ranger <- imputations_performance(target27,  "dataset27", "classif.ranger") 
evaluation_188_ranger <- imputations_performance(target188, "dataset188", "classif.ranger") 
evaluation_29_ranger <- imputations_performance(target29, "dataset29", "classif.ranger")
evaluation_4_ranger <- imputations_performance(target4,  "dataset4", "classif.ranger")
# evaluation_4_ranger <- rep(NA, 5)
##### RZUCA DZIWNY BŁĄD

############################### PROBLEMY: 1018
# evaluation_1018 <- imputations_performance(dataset1018,target1018)

```

```{r ranger 2, results='hide'}
evaluation_40536_ranger <- imputations_performance(target40536,  "dataset40536", "classif.ranger")  
```

```{r ranger 3, results='hide'}
# evaluation_23381 <- imputations_performance(target23381, "dataset23381", "classif.ranger") # nie działa :( 
```

```{r ranger 4, results='hide'}
### do sprawdzenia, długo sie robi ale moze pojdzie 
evaluation_6332_ranger <- imputations_performance(target6332, "dataset6332", "classif.ranger") 
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r ranger 5, results='hide'}
evaluation_1590_ranger <- imputations_performance(target1590, "dataset1590", "classif.ranger")  
```

```{r f1 ranger, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
f1_combined_ranger<-as.data.frame(
  rbind(
  evaluation_1590_ranger$f1,
  evaluation_188_ranger$f1,
  #evaluation_23381$auc,
  evaluation_27_ranger$f1,
  evaluation_29_ranger$f1,
  evaluation_38_ranger$f1,
  evaluation_4_ranger$f1,
  # evaluation_4_ranger,
  evaluation_40536_ranger$f1,
  #evaluation_41278_ranger$f1,
  evaluation_55_ranger$f1,
  evaluation_56_ranger$f1,
  evaluation_6332_ranger$f1,
  evaluation_944_ranger$f1
))
rownames(f1_combined_ranger) <- NULL
colnames(f1_combined_ranger)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
f1_combined_ranger<-cbind(data_name, f1_combined_ranger)

```

```{r tab4, resuls='hide'}
knitr::kable(f1_combined_ranger, caption = "Tab.4. Ranger results")
```

### Rating Ranger

```{r rating ranger, results='hide'}
ranking_ranger<-ranking(f1_combined_ranger)
ranking_ranger_melt<-melt(ranking_ranger%>%select(-mean))

ggplot(ranking_ranger_melt, aes(x = imputation, y = value)) +
  geom_boxplot()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
  
```



### Results LDA 

```{r lda 1, results='hide'}

# variables are collinear
evaluation_944_lda <- imputations_performance(target944, "dataset944", "classif.lda")   
evaluation_56_lda <- imputations_performance(target56, "dataset56", "classif.lda") 
evaluation_55_lda <- imputations_performance(target55,  "dataset55", "classif.lda")  
evaluation_38_lda <- imputations_performance(target38,  "dataset38", "classif.lda")  
evaluation_27_lda <- imputations_performance(target27,  "dataset27", "classif.lda") 
evaluation_188_lda <- imputations_performance(target188, "dataset188", "classif.lda")
evaluation_29_lda <- imputations_performance(target29, "dataset29", "classif.lda") 
evaluation_4_lda <- imputations_performance(target4,  "dataset4", "classif.lda") # TEN SAM BŁĄD CO WYŻEJ 
# evaluation_4_lda <- rep(NA, 5)
############################### PROBLEMY: 1018
# evaluation_1018 <- imputations_performance(dataset1018,target1018)
# przy rm rows zeruje sie zbiór testowy
# przy mice nie działa dla "pmm"


```

```{r lda 2, results='hide'}
evaluation_40536_lda <- imputations_performance(target40536,  "dataset40536", "classif.lda")  
```

```{r lda 3, results='hide'}
# evaluation_23381 <- imputations_performance(target23381, "dataset23381", "classif.lda") # nie działa :( 
```

```{r lda 4, results='hide'}
### do sprawdzenia, długo sie robi ale moze pojdzie 
evaluation_6332_lda <- imputations_performance(target6332, "dataset6332", "classif.lda") # bład przy modelu na mice
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r lda 5, results='hide'}
evaluation_1590_lda <- imputations_performance(target1590, "dataset1590", "classif.lda") # robi sie 
```

```{r f1 lda, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
f1_combined_lda<-as.data.frame(
  rbind(
  evaluation_1590_lda$f1,
  evaluation_188_lda$f1,
  #evaluation_23381$auc,
  evaluation_27_lda$f1,
  evaluation_29_lda$f1,
  evaluation_38_lda$f1,
  evaluation_4_lda$f1,
  # evaluation_4_lda,
  evaluation_40536_lda$f1,
  #evaluation_41278_lda$f1,
  evaluation_55_lda$f1,
  evaluation_56_lda$f1,
  evaluation_6332_lda$f1,
  evaluation_944_lda$f1
))
rownames(f1_combined_lda) <- NULL
colnames(f1_combined_lda)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
f1_combined_lda<-cbind(data_name, f1_combined_lda)

```

```{r tab5, resuls='hide'}
knitr::kable(f1_combined_lda, caption = "Tab.5. LDA results")
```

### Rating LDA

```{r rating lda, results='hide'}
ranking_lda<-ranking(f1_combined_lda)
ranking_lda_melt<-melt(ranking_lda%>%select(-mean))

ggplot(ranking_lda_melt, aes(x = imputation, y = value)) +
  geom_boxplot()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
  
```


### Results KNN 

```{r kknn 1, results='hide'}

evaluation_944_kknn <- imputations_performance(target944, "dataset944", "classif.kknn") 
evaluation_56_kknn <- imputations_performance(target56, "dataset56", "classif.kknn") 
evaluation_55_kknn <- imputations_performance(target55,  "dataset55", "classif.kknn")  
evaluation_38_kknn <- imputations_performance(target38,  "dataset38", "classif.kknn")  
evaluation_27_kknn <- imputations_performance(target27,  "dataset27", "classif.kknn")  
evaluation_188_kknn <- imputations_performance(target188, "dataset188", "classif.kknn") 
evaluation_29_kknn <- imputations_performance(target29, "dataset29", "classif.kknn")
evaluation_4_kknn <- imputations_performance(target4,  "dataset4", "classif.kknn")  # BŁAD
# evaluation_4_kknn <- rep(NA, 5)

############################### PROBLEMY: 1018
# evaluation_1018 <- imputations_performance(dataset1018,target1018)
# przy rm rows zeruje sie zbiór testowy
# przy mice nie działa dla "pmm"


```

```{r kknn 2, results='hide'}
evaluation_40536_kknn <- imputations_performance(target40536,  "dataset40536", "classif.kknn") # robi sie 
```

```{r kknn 3, results='hide'}
# evaluation_23381 <- imputations_performance(target23381, "dataset23381", "classif.kknn") # nie działa :( 
```

```{r kknn 4, results='hide'}
### do sprawdzenia, długo sie robi ale moze pojdzie 
evaluation_6332_kknn <- imputations_performance(target6332, "dataset6332", "classif.kknn") # bład przy modelu na mice
# jak pojdzie to odkomentowac w miarach !!!
# błąd - missing data in columns
```

```{r kknn 5, results='hide'}
evaluation_1590_kknn <- imputations_performance(target1590, "dataset1590", "classif.kknn") # robi sie 
```

```{r f1 kknn, results= 'markup'}
# 1590, 188, 23381, 27, 29, 38, 4, 40536, 55, 56, 6332, 944
f1_combined_kknn<-as.data.frame(
  rbind(
  evaluation_1590_kknn$f1,
  evaluation_188_kknn$f1,
  #evaluation_23381$auc,
  evaluation_27_kknn$f1,
  evaluation_29_kknn$f1,
  evaluation_38_kknn$f1,
  evaluation_4_kknn$f1,
  # evaluation_4_kknn,
  evaluation_40536_kknn$f1,
  #evaluation_41278_kknn$f1,
  evaluation_55_kknn$f1,
  evaluation_56_kknn$f1,
  evaluation_6332_kknn$f1,
  evaluation_944_kknn$f1
))
rownames(f1_combined_kknn) <- NULL
colnames(f1_combined_kknn)<-c('insert_mean','mice_pmm','vim_knn','vim_hotdeck','softImpute')
f1_combined_kknn<-cbind(data_name, f1_combined_kknn)

```

```{r tab6, resuls='hide'}
knitr::kable(f1_combined_kknn, caption = "Tab.6. KNN results")
```

###  Rating KKNN

```{r rating kknn, results='hide'}
ranking_kknn<-ranking(f1_combined_kknn)
ranking_kknn_melt<-melt(ranking_kknn%>%select(-mean))

ggplot(ranking_kknn_melt, aes(x = imputation, y = value)) +
  geom_boxplot()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
  
```

## Rating summary

```{r rating summary}

ranking_combined<-as.data.frame(cbind(
  rpart=ranking_rpart$mean,
  nb=ranking_nb$mean,
  ranger=ranking_ranger$mean,
  lda=ranking_lda$mean,
  kknn=ranking_kknn$mean))
row.names(ranking_combined)<-ranking_rpart$imputation



heatmap(as.matrix(ranking_combined))

```


## References 

1. mice package https://cran.r-project.org/web/packages/mice/index.html

2. VIM package https://cran.r-project.org/web/packages/VIM/index.html

3. softImpute package https://cran.r-project.org/web/packages/softImpute/index.html

4. mlr3 package https://mlr3.mlr-org.com/